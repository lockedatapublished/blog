<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Best Practices on Locke Data Blog</title>
    <link>https://itsalocke.com/blog/tags/best-practices/</link>
    <description>Recent content in Best Practices on Locke Data Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <copyright>&lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;&lt;img alt=&#34;Creative Commons License&#34; style=&#34;border-width:0&#34; src=&#34;https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png&#34; /&gt;&lt;/a&gt;&lt;br /&gt;This work is licensed under a &lt;a rel=&#34;license&#34; href=&#34;http://creativecommons.org/licenses/by-nc-sa/4.0/&#34;&gt;Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License&lt;/a&gt;.</copyright>
    <lastBuildDate>Fri, 26 May 2017 08:00:04 +0000</lastBuildDate>
    
	<atom:link href="https://itsalocke.com/blog/tags/best-practices/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Versioning R model objects in SQL Server</title>
      <link>https://itsalocke.com/blog/versioning-r-model-objects-in-sql-server/</link>
      <pubDate>Fri, 26 May 2017 08:00:04 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/versioning-r-model-objects-in-sql-server/</guid>
      <description>High-level info If you build a model and never update it you&amp;#8217;re missing a trick. Behaviours change so your model will tend to perform worse over time. You&amp;#8217;ve got to regularly refresh it, whether that&amp;#8217;s adjusting the existing model to fit the latest data (recalibration) or building a whole new model (retraining), but this means you&amp;#8217;ve got new versions of your model that you have to handle. You need to think about your methodology for versioning R model objects, ideally before you lose any versions.</description>
    </item>
    
    <item>
      <title>Improving automatic document production with R</title>
      <link>https://itsalocke.com/blog/improving-automatic-document-production-with-r/</link>
      <pubDate>Fri, 19 May 2017 08:02:26 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/improving-automatic-document-production-with-r/</guid>
      <description>In this post, I describe the latest iteration of my automatic document production with R. It improves upon the methods used in Rtraining, and previous work on this topic can read by going to the auto deploying R documentation tag.
I keep banging on about this area because reproducible research / analytical document pipelines is an area I&amp;#8217;ve a keen interest in. I see it as a core part of DataOps as it&amp;#8217;s vital for helping us ensure our models and analysis are correct in data science and boosting our productivity.</description>
    </item>
    
    <item>
      <title>The making of datasauRus</title>
      <link>https://itsalocke.com/blog/the-making-of-datasaurus/</link>
      <pubDate>Tue, 02 May 2017 12:10:32 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/the-making-of-datasaurus/</guid>
      <description>Around 8:30pm I saw this tweet and duly retweeted
https://t.co/WuyU9D6npK  &amp;mdash; Richie Cotton (@richierocks) May 1, 2017  It turns out awesome folks, George and Justin, had made a process whereby they can generate different distributions of points that retain the same summary statistics. They used this process for making some friends for Dino the Datasaurus who was created by Alberto Cairo. They made the data for Dino and the rest of the Datasaurus Dozen available for download.</description>
    </item>
    
    <item>
      <title>R Quick Tip: Table parameters for rmarkdown reports</title>
      <link>https://itsalocke.com/blog/r-quick-tip-table-parameters-for-rmarkdown-reports/</link>
      <pubDate>Wed, 19 Apr 2017 08:50:30 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/r-quick-tip-table-parameters-for-rmarkdown-reports/</guid>
      <description>The recent(ish) advent of parameters in rmarkdown reports is pretty nifty but there&amp;#8217;s a little bit of behaviour that can come in handy but doesn&amp;#8217;t come across in the documentation. You can use table parameters for rmarkdown reports.
Previously, if you wanted to produce multiple reports based off a dataset, you would make the dataset available and then perform filtering in the report. Now we can pass the filtered data directly to the report, which keeps all the filtering logic in one place.</description>
    </item>
    
    <item>
      <title>Talking Data and Docker</title>
      <link>https://itsalocke.com/blog/talking-data-and-docker/</link>
      <pubDate>Wed, 08 Feb 2017 16:25:20 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/talking-data-and-docker/</guid>
      <description>If you need to know about persisting data in the world of containers then I recently did a talk and a spot on a podcast that should help you out. My NDC London talk Data + Docker = Disconbobulating? cover the basics and architectural decisions. In my podcast spot Data and Docker on .Net Rocks we go into more depth about the architectural decisions facing you when working with data and Docker.</description>
    </item>
    
    <item>
      <title>CRISP-DM and why you should know about it</title>
      <link>https://itsalocke.com/blog/crisp-dm-and-why-you-should-know-about-it/</link>
      <pubDate>Fri, 13 Jan 2017 15:28:32 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/crisp-dm-and-why-you-should-know-about-it/</guid>
      <description>&lt;p&gt;The Cross Industry Standard Process for Data Mining (CRISP-DM) was a concept developed 20 years ago now. I&amp;#8217;ve read about it in various data mining and related books and it&amp;#8217;s come in very handy over the years. In this post, I&amp;#8217;ll outline what the model is and why you should know about it, even if it has that terribly out of vogue phrase data mining in it! ðŸ˜‰&lt;/p&gt;

&lt;blockquote class=&#34;twitter-tweet&#34; data-width=&#34;525&#34;&gt;
  &lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
    Data / R people. Do you know what the CRISP-DM model is?
  &lt;/p&gt;
  
  &lt;p&gt;
    &amp;mdash; Steph Locke (@SteffLocke) &lt;a href=&#34;https://twitter.com/SteffLocke/status/818148292060213250&#34;&gt;January 8, 2017&lt;/a&gt;
  &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sponsoring community events (SCE)</title>
      <link>https://itsalocke.com/blog/sponsoring-community-events-sce/</link>
      <pubDate>Mon, 01 Aug 2016 09:00:10 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/sponsoring-community-events-sce/</guid>
      <description>Sponsoring community events &amp;#8211; is it right for you? This series of posts will take you through the things you need to know to help you decide.
Over the coming weeks, this new series will go through the in&amp;#8217;s and out&amp;#8217;s of sponsoring community events. Community events are fantastic from an attendee perspective, but when you&amp;#8217;re handing over cash you need to know what you&amp;#8217;re letting yourself in for and how you get return on investment (ROI).</description>
    </item>
    
    <item>
      <title>Use your .Rprofile to give you important notifications</title>
      <link>https://itsalocke.com/blog/use-your-.rprofile-to-give-you-important-notifications/</link>
      <pubDate>Thu, 23 Jun 2016 09:08:43 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/use-your-.rprofile-to-give-you-important-notifications/</guid>
      <description>In R, we can use a file called .Rprofile to do things in R based on a number of triggers. One thing I&amp;#8217;ve done is give myself a DIY notification of how many data breaches I&amp;#8217;ve been involved in!
First of all, you need a file called .Rprofile that&amp;#8217;s stored in your working directory. Some useful resources about .Rprofiles can be found on .Rprofile CRAN docs and an .Rprofile intro.</description>
    </item>
    
    <item>
      <title>Shiny module design patterns: Pass module inputs to other modules</title>
      <link>https://itsalocke.com/blog/shiny-module-design-patterns-pass-module-inputs-to-other-modules/</link>
      <pubDate>Tue, 19 Apr 2016 10:15:19 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/shiny-module-design-patterns-pass-module-inputs-to-other-modules/</guid>
      <description>&lt;p&gt;Continuing in the series of &lt;a href=&#34;https://itsalocke.com/tag/shiny-design-patterns/&#34;&gt;shiny module design patterns&lt;/a&gt;, this post covers how to pass all the inputs from one module to another.&lt;/p&gt;

&lt;h2 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h2&gt;

&lt;p&gt;Return &lt;code&gt;input&lt;/code&gt; from within the server call. Store the &lt;code&gt;callModule()&lt;/code&gt; result in a variable. Pass the variable into arguments for other modules. Access the variable like you would &lt;code&gt;input&lt;/code&gt;. &lt;a href=&#34;https://github.com/stephlocke/shinymodulesdesignpatterns&#34;&gt;Steal the code&lt;/a&gt; and, as always, if you can improve it do so!&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Shiny module design patterns: Pass module input to other modules</title>
      <link>https://itsalocke.com/blog/shiny-module-design-patterns-pass-module-input-to-other-modules/</link>
      <pubDate>Thu, 14 Apr 2016 12:05:55 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/shiny-module-design-patterns-pass-module-input-to-other-modules/</guid>
      <description>&lt;p&gt;Following on from looking at the &lt;a href=&#34;https://itsalocke.com/shiny-module-design-pattern-pass-inputs-one-module-another/&#34;&gt;shiny modules design pattern of passing an input value to many modules&lt;/a&gt;, I&amp;#8217;m now going to look at a more complex shiny module design pattern: passing an input from one module to another.&lt;/p&gt;

&lt;h2 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h2&gt;

&lt;p&gt;Return the input in a reactive expression from within the server call. Store the &lt;code&gt;callModule()&lt;/code&gt; result in a variable. Pass the variable into arguments for other modules. &lt;a href=&#34;https://github.com/stephlocke/shinymodulesdesignpatterns&#34;&gt;Steal the code&lt;/a&gt; and, as always, if you can improve it do so!&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Shiny module design patterns: Pass a single input to multiple modules</title>
      <link>https://itsalocke.com/blog/shiny-module-design-patterns-pass-a-single-input-to-multiple-modules/</link>
      <pubDate>Fri, 08 Apr 2016 10:56:32 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/shiny-module-design-patterns-pass-a-single-input-to-multiple-modules/</guid>
      <description>&lt;p&gt;For the awesome &lt;a href=&#34;https://www.eventbrite.com/e/shiny-developer-conference-registration-19153967031&#34;&gt;Shiny Developers Conference&lt;/a&gt; back in January, I endeavoured to learn about shiny modules and &lt;a href=&#34;https://itsalocke.com/declutter-a-shiny-reports-code-v2-0/&#34;&gt;overhaul an application&lt;/a&gt; using them in the space of two days. I succeeded and almost immediately switched onto other projects, thereby losing most of the hard-won knowledge! As I rediscover shiny modules and start putting them into more active use, I&amp;#8217;ll be blogging about design patterns. This post takes you through the case of multiple modules receiving the same input value.&lt;/p&gt;

&lt;h2 id=&#34;tl-dr&#34;&gt;TL;DR&lt;/h2&gt;

&lt;p&gt;Stick overall config input objects at the app level and pass them in a reactive expression to &lt;code&gt;callModule()&lt;/code&gt;. Pass the results in as an extra argument into subsequent modules. These are reactive so don&amp;#8217;t forget the brackets. &lt;a href=&#34;https://github.com/stephlocke/shinymodulesdesignpatterns&#34;&gt;Steal the code&lt;/a&gt; and, as always, if you can improve it do so!&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Auto-deploying documentation: better change tracking of artefacts</title>
      <link>https://itsalocke.com/blog/auto-deploying-documentation-better-change-tracking-of-artefacts/</link>
      <pubDate>Mon, 04 Apr 2016 11:04:34 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/auto-deploying-documentation-better-change-tracking-of-artefacts/</guid>
      <description>&lt;p&gt;As part of my never-ending quest to deploy documentation better, I&amp;#8217;ve made yet another tweak to my scripts that deploy R vignettes or Rmarkdown documents to the &lt;code&gt;gh-pages&lt;/code&gt; branch of my github repositories via Travis-CI.&lt;/p&gt;

&lt;p&gt;The script from &lt;a href=&#34;http://rmflight.github.io/posts/2014/11/travis_ci_gh_pages.html&#34;&gt;Robert Flight&lt;/a&gt; that&amp;#8217;s provided the basis for most of this work does something specific to update the web facing branch of the repository. It would:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Create a blank repository&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Add the requisite files to the repository&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Add and commit them to the repo&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Force the repo to overwrite the &lt;code&gt;gh-pages&lt;/code&gt; branch&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This had the unfortunate consequence of losing the history of what was previously hosted on the branch and could not tell me what commit to my development branches was responsible for a version of the docs. It took a little bit of playing but the revised script now:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Clones the gh-pages branch&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Adds the requisite files into the reports&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Add and commit them to the repo&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Push the changes&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Using an environment variable ($TRAVIS_COMMIT) the commit message is the commit ID for the latest commit in the build that occurs on Travis, making it very easy to see what changes triggered a documentation update.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>mockaRoo â€“ making realistic test data in R</title>
      <link>https://itsalocke.com/blog/mockaroo--making-realistic-test-data-in-r/</link>
      <pubDate>Tue, 08 Mar 2016 14:00:54 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/mockaroo--making-realistic-test-data-in-r/</guid>
      <description>&lt;p&gt;When I&amp;#8217;m building stuff in R like packages, models, etc. I find myself wishing for realistic looking test data without having to resort to getting data off my production server. To that end I&amp;#8217;ve been on the hunt for a way of generating decent test data. A few months back I stumbled upon the neat system &lt;a href=&#34;https://www.mockaroo.com/&#34;&gt;Mockaroo&lt;/a&gt; which provides a GUI to build some data that suits your needs.&lt;/p&gt;

&lt;p&gt;Mockaroo is a really impressive service with a wide spread of different data types. They also have simple ways of adding things like within group differences to data so that you can mock realistic class differences. They use the freemium model so you can get a thousand rows per download, which is pretty sweet. The big BUT you can feel coming on is this &amp;#8211; it&amp;#8217;s a GUI! I don&amp;#8217;t want to have spend time hand cranking a data extract.&lt;/p&gt;

&lt;p&gt;Thankfully, they have a GUI for getting data too and it&amp;#8217;s pretty simply to use so I&amp;#8217;ve started making a package for it.&lt;/p&gt;

&lt;p&gt;I&amp;#8217;ve started the package on &lt;a href=&#34;https://github.com/stephlocke/mockaRoo&#34;&gt;github&lt;/a&gt; and will be developing it over the next month or two. It&amp;#8217;s up and working, but only in the most primitive way as I&amp;#8217;d like to get some feedback from folks who might find this useful around how the interface for generating your desired data schema should work.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Auto-deploying documentation: Rtraining</title>
      <link>https://itsalocke.com/blog/auto-deploying-documentation-rtraining/</link>
      <pubDate>Wed, 23 Dec 2015 10:25:48 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/auto-deploying-documentation-rtraining/</guid>
      <description>In my last post on using GitHub, Travis-CI, and rmarkdown/knitr for automatically building and deploying documentation, I covered how I was able to do it with a containerised approach so things were faster. I also said my Rtraining repository was still too brittle to blog about. This has changed &amp;#8211; WOO HOO!
The main thanks for that goes out to the new package ezknitr from Dean Attali. ezknitr takes the pain out of working directories, making my hierarchies much more resilient.</description>
    </item>
    
    <item>
      <title>Auto-deploying documentation: FASTER!</title>
      <link>https://itsalocke.com/blog/auto-deploying-documentation-faster/</link>
      <pubDate>Fri, 13 Nov 2015 09:13:22 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/auto-deploying-documentation-faster/</guid>
      <description>&lt;p&gt;Over the past few years I&amp;#8217;ve been delving deeper into automatically building and deploying documentation and reporting in R (with rmarkdown, LaTeX etc). This post covers another step forward on that journey towards awesomeness.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DataOps â€“ itâ€™s a thing (honest)</title>
      <link>https://itsalocke.com/blog/dataops--its-a-thing-honest/</link>
      <pubDate>Fri, 16 Oct 2015 20:27:03 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/dataops--its-a-thing-honest/</guid>
      <description>&lt;p&gt;Today, I presented a &lt;a href=&#34;https://1drv.ms/p/s!AiZm2P6YHtSfjye0xDn_fuL80eSp&#34;&gt;lightning talk on DataOps&lt;/a&gt; at &lt;a href=&#34;http://sqlinthecity.red-gate.com/london-2015/&#34;&gt;SQL in the City&lt;/a&gt;. It was a fantastic day and a great opportunity to catch up with how the database side of things is evolving to embrace &lt;a href=&#34;https://en.wikipedia.org/wiki/DevOps&#34;&gt;DevOps&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;My lightning talk was titled &lt;em&gt;DataOps &amp;#8211; it&amp;#8217;s a thing (honest)&lt;/em&gt; and focused on what is essentially DevOps ported out of the developer sphere and into the data professional sphere.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Auto-deploying documentation: multiple R vignettes</title>
      <link>https://itsalocke.com/blog/auto-deploying-documentation-multiple-r-vignettes/</link>
      <pubDate>Fri, 05 Jun 2015 08:38:44 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/auto-deploying-documentation-multiple-r-vignettes/</guid>
      <description>&lt;p&gt;Following on from my post about the principles behind using travis-ci to commit to a &lt;code&gt;gh-pages&lt;/code&gt; I wanted to follow-up with how I tackled my &amp;#8220;intermediate&amp;#8221; use case.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;posts-in-this-series&#34;&gt;Posts in this series&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://itsalocke.com/automated-documentation-hosting-on-github-via-travis-ci/&#34;&gt;Automated documentation hosting on github via Travis-CI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://itsalocke.com/auto-deploying-documentation-multiple-r-vignettes/&#34;&gt;Auto-deploying documentation: multiple R vignettes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://itsalocke.com/auto-deploying-documentation-faster/&#34;&gt;Auto-deploying documentation: FASTER!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://itsalocke.com/auto-deploying-documentation-rtraining/&#34;&gt;Auto-deploying documentation: Rtraining&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://itsalocke.com/auto-deploying-documentation-better-change-tracking-artefacts/&#34;&gt;Auto-deploying documentation: better change tracking of artefacts&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;multiple-vignettes&#34;&gt;Multiple vignettes&lt;/h2&gt;

&lt;p&gt;In &lt;a href=&#34;https://itsalocke.com/automated-documentation-hosting-on-github-via-travis-ci/&#34;&gt;my original post&lt;/a&gt; I show how I pushed the tfsR vignette to &lt;code&gt;gh-pages&lt;/code&gt;, which involved copying it and renaming it to index.html.&lt;/p&gt;

&lt;p&gt;Unfortunately, this wouldn&amp;#8217;t work if I had multiple vignettes that I wanted to be accessible online.&lt;/p&gt;

&lt;h3 id=&#34;requirements&#34;&gt;Requirements&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;An index.html file&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A way of extracting any number of html files from the vignette folder&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Automated documentation hosting on github via Travis-CI</title>
      <link>https://itsalocke.com/blog/automated-documentation-hosting-on-github-via-travis-ci/</link>
      <pubDate>Mon, 01 Jun 2015 09:29:21 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/automated-documentation-hosting-on-github-via-travis-ci/</guid>
      <description>&lt;p&gt;In this post, I&amp;#8217;m going to cover how you can use continuous integration and source control to build and host documentation (or any other static HTML) for free, and in a way that updates every time your code changes. I&amp;#8217;ll cover the generic capability, and then how I apply this to my simplest package, tfsR. In a later post (once I&amp;#8217;ve cracked the best method to do it) I&amp;#8217;ll cover my more complex use case of multiple documents and a dynamically constructed index page.&lt;/p&gt;

&lt;p&gt;NB: This is kicked off from a &lt;a href=&#34;http://rmflight.github.io/posts/2014/11/travis_ci_gh_pages.html&#34;&gt;post&lt;/a&gt; from Robert Flight about applying to the technique to R package vignettes. It&amp;#8217;s a very useful post but it was quite specific to his situation and I wanted to understand the principles behind it before I started extending it to my more complex cases.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&#34;posts-in-this-series&#34;&gt;Posts in this series&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://itsalocke.com/automated-documentation-hosting-on-github-via-travis-ci/&#34;&gt;Automated documentation hosting on github via Travis-CI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://itsalocke.com/auto-deploying-documentation-multiple-r-vignettes/&#34;&gt;Auto-deploying documentation: multiple R vignettes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://itsalocke.com/auto-deploying-documentation-faster/&#34;&gt;Auto-deploying documentation: FASTER!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://itsalocke.com/auto-deploying-documentation-rtraining/&#34;&gt;Auto-deploying documentation: Rtraining&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://itsalocke.com/auto-deploying-documentation-better-change-tracking-artefacts/&#34;&gt;Auto-deploying documentation: better change tracking of artefacts&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;requirements&#34;&gt;Requirements&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Must haves:

&lt;ul&gt;
&lt;li&gt;Travis-CI&lt;/li&gt;
&lt;li&gt;GitHub&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Optional:

&lt;ul&gt;
&lt;li&gt;A linux machine (so you can test your bash script that Travis-CI will run)&lt;/li&gt;
&lt;li&gt;R (for following the specific instructions)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;high-level-process&#34;&gt;High-level process&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Get an OAUTH token from github&lt;/li&gt;
&lt;li&gt;Add OAUTH token to travis&lt;/li&gt;
&lt;li&gt;Add a *.sh file that gets your HTML (depending on circumstance, you may also need to generate it) and pushes to gh-pages branch&lt;/li&gt;
&lt;li&gt;Include your .sh file in the &lt;code&gt;after_success&lt;/code&gt; part of your travis file&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Commit &amp;amp; push!&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Database / BI related unit testing options</title>
      <link>https://itsalocke.com/blog/database-/-bi-related-unit-testing-options/</link>
      <pubDate>Thu, 06 Nov 2014 16:18:48 +0000</pubDate>
      
      <guid>https://itsalocke.com/blog/database-/-bi-related-unit-testing-options/</guid>
      <description>A quick list of frameworks available for doing unit testing, based on what I covered in today&amp;#8217;s SQL Lunch
MSFT Database projects Purpose: unit testing database objects
Method: SQL / GUI
Site: http://msdn.microsoft.com/en-us/library/jj851200(v=vs.103).aspx
Cost: Free
Pros: Built-in, quite well documented
Cons: Requires Visual Studio 2010 Pro or above
Codeplex ssisUnit Purpose: SSIS unit testing
Method: XML / GUI
Site: https://ssisunit.codeplex.com
Cost: Free
Pros: Unique
Cons: As of writing, only stable version was released in 2008</description>
    </item>
    
  </channel>
</rss>